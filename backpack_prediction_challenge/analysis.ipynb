{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle competitions download -c playground-series-s5e2\n",
    "!unzip -u *.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import missingno\n",
    "\n",
    "from sklearn import set_config\n",
    "set_config(transform_output = \"pandas\")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error\n",
    "from sklearn.model_selection import ShuffleSplit, KFold\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder, StandardScaler\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "\n",
    "KAGGLE_RUN = False\n",
    "if KAGGLE_RUN:\n",
    "    working_dir = Path('/kaggle/input/playground-series-s5e2')\n",
    "else:\n",
    "    working_dir = Path().cwd()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.concat([\n",
    "    pd.read_csv(working_dir/'train.csv', index_col='id'),\n",
    "    pd.read_csv(working_dir/'training_extra.csv', index_col='id')\n",
    "    ])\n",
    "\n",
    "test_df = pd.read_csv(working_dir/'test.csv')\n",
    "\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORIC_COLUMNS = ['Brand', 'Material', 'Size', 'Compartments', 'Laptop Compartment', 'Waterproof', 'Style', 'Color']\n",
    "NUMERIC_COLUMNS = ['Weight Capacity (kg)']\n",
    "TARGET_COLUMN = ['Price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_vals(df:pd.DataFrame, column:str) -> None:\n",
    "    print(f'{column} has the following unique entries {len(df[column].unique())}')\n",
    "    print(f'{df[column].value_counts()}')\n",
    "    print('-----------------------------------')\n",
    "\n",
    "\n",
    "for column in CATEGORIC_COLUMNS:\n",
    "    get_unique_vals(train_df, column)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missingno.matrix(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missingno.heatmap(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values_train = pd.DataFrame({\n",
    "    'Feature': train_df.columns,\n",
    "    'No. of Missing Values': train_df.isnull().sum().values,\n",
    "    '% of Missing Values': ((train_df.isnull().sum().values)/len(train_df)*100)\n",
    "    })\n",
    "missing_values_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=2, ncols=3, figsize=(18,10))\n",
    "\n",
    "sns.histplot(data=train_df, x='Compartments', ax=ax[0,0])\n",
    "sns.histplot(data=train_df, x='Weight Capacity (kg)', ax=ax[0,1])\n",
    "sns.histplot(data=train_df, x='Price', ax=ax[0,2])\n",
    "\n",
    "sns.boxplot(data=train_df, x='Compartments', ax=ax[1,0])\n",
    "sns.boxplot(data=train_df, x='Weight Capacity (kg)', ax=ax[1,1])\n",
    "sns.boxplot(data=train_df, x='Price', ax=ax[1,2])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=len(CATEGORIC_COLUMNS), ncols=1, figsize=(10,18))\n",
    "\n",
    "\n",
    "for i, category in enumerate(CATEGORIC_COLUMNS):\n",
    "    sns.countplot(\n",
    "        data=train_df[[category]],\n",
    "        x=category,\n",
    "        ax=ax[i]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation = train_df[NUMERIC_COLUMNS+['Compartments']].corr()\n",
    "\n",
    "mask = np.triu(np.ones_like(correlation, dtype=bool))\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(9,9))\n",
    "\n",
    "cmap = sns.diverging_palette(230, 20, as_cmap=True)\n",
    "sns.heatmap(\n",
    "    correlation,\n",
    "    mask=mask,\n",
    "    cmap=cmap,\n",
    "    annot=True,\n",
    "    square=True, \n",
    "    ax=ax\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nan Handling\n",
    "# for the time being, drop, reinvestigate others later\n",
    "\n",
    "print(train_df.isna().sum().values)\n",
    "train_df = train_df.dropna()\n",
    "print(train_df.isna().sum().values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature engineering\n",
    "# add combinations of categories\n",
    "# or transform numerics in categories/bins\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "target = train_df[TARGET_COLUMN]\n",
    "train = train_df.drop(columns=TARGET_COLUMN)\n",
    "test = test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('categories', OneHotEncoder(sparse_output=False), CATEGORIC_COLUMNS),\n",
    "        ('weight', MinMaxScaler(), ['Weight Capacity (kg)']),\n",
    "    ], remainder='passthrough'\n",
    ")\n",
    "\n",
    "pipe = Pipeline(\n",
    "    steps=[\n",
    "        ('transform_columns', transformer),\n",
    "        ('regression', RandomForestRegressor())\n",
    "        ]\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results_tree_regressor = cross_validate(\n",
    "    pipe,\n",
    "    train,\n",
    "    target,\n",
    "    cv=KFold(n_splits=10, shuffle=True, random_state=42),\n",
    "    scoring=\"neg_root_mean_squared_error\",\n",
    "    n_jobs=6\n",
    ")\n",
    "\n",
    "errors_tree_regressor = pd.Series(\n",
    "    -cv_results_tree_regressor[\"test_score\"], name=\"Decision tree regressor\"\n",
    ")\n",
    "errors_tree_regressor.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "cv_search = GridSearchCV(\n",
    "    estimator = pipe,\n",
    "    param_grid={\n",
    "        'regression__n_estimators':[100],\n",
    "        'regression__criterion':['squared_error', 'friedman_mse', 'poisson'],\n",
    "    },\n",
    "    scoring=\"neg_root_mean_squared_error\",\n",
    "    n_jobs=3,\n",
    ")\n",
    "\n",
    "search_results = cv_search.fit(\n",
    "    train,\n",
    "    target\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df = pd.DataFrame(\n",
    "    index=test.index,\n",
    "    data={\n",
    "        'num_sold':cv_search.predict(test)\n",
    "    }\n",
    ")\n",
    "sub_df    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if KAGGLE_RUN:\n",
    "    sub_df.to_csv(\"/kaggle/working/submission.csv\")\n",
    "    !head /kaggle/working/submission.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
